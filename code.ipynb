{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GETTING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as requests\n",
    "import pandas as pd\n",
    "import re # for regular expressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingValue = []\n",
    "reviewTitle = []\n",
    "location = []\n",
    "reviewArticle = []\n",
    "\n",
    "for i in range(1,201): # Scrape 200 pages\n",
    "    try:\n",
    "        URL = f\"https://www.airlinequality.com/airline-reviews/british-airways/page/{i}/\"\n",
    "        page = requests.get(URL)\n",
    "        page = page.content\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        all_reviews = soup.find_all(\"article\", itemprop=\"review\")\n",
    "\n",
    "        \n",
    "        for review_element in all_reviews:\n",
    "            ratingValues = review_element.find(\"span\", itemprop=\"ratingValue\").text.strip()\n",
    "            ratingValue.append(ratingValues)\n",
    "\n",
    "            reviewTitles = review_element.find(\"h2\", class_=\"text_header\").text.strip()\n",
    "            reviewTitle.append(reviewTitles)\n",
    "\n",
    "            locations = review_element.find(\"h3\", class_=\"text_sub_header\").text.strip()\n",
    "            location.append(locations)\n",
    "\n",
    "            reviewArticles = review_element.find(\"div\", class_=\"text_content\").text.strip()\n",
    "            reviewArticle.append(reviewArticles)\n",
    "\n",
    "        print(\"Page \", i, \" complete\") # To know number of pages scraped \n",
    "        print(len(ratingValue), \"reviews scraped\") # To know number of reviews scraped\n",
    "    except AttributeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"ratingValue\":ratingValue, \"reviewTitle\":reviewTitle, \"location\":location, \"reviewArticle\":reviewArticle})\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSPECTING AND CLEANING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23490\\Documents\\my portfolio\\BA Virtual Internship\\My method BA virtual copy.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info() # Get to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.duplicated()) # Check for duplicated items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>location</th>\n",
       "      <th>reviewArticle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>\"sufficient leg and arm room\"</td>\n",
       "      <td>Graeme Boothman (United Kingdom) 8th November ...</td>\n",
       "      <td>✅ Trip Verified |  Booked online months ago an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>“crew were polite”</td>\n",
       "      <td>R Vines (United Kingdom) 7th November 2023</td>\n",
       "      <td>✅ Trip Verified |  The flight was on time. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Angry, disappointed, and unsatisfied\"</td>\n",
       "      <td>Massimo Tricca (Italy) 5th November 2023</td>\n",
       "      <td>Not Verified |  Angry, disappointed, and unsat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"BA now stands for Basic Airways\"</td>\n",
       "      <td>J Kaye (United Kingdom) 5th November 2023</td>\n",
       "      <td>✅ Trip Verified |  As an infrequent flyer, Bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>\"A totally unremarkable flight\"</td>\n",
       "      <td>M Collie (Ireland) 4th November 2023</td>\n",
       "      <td>Not Verified |  A totally unremarkable flight,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>3</td>\n",
       "      <td>\"another underwhelming experience\"</td>\n",
       "      <td>Clive Drake (United Kingdom) 13th November 2016</td>\n",
       "      <td>✅ Verified Review |  The flight started in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>3</td>\n",
       "      <td>\"underwhelming due to bean counters\"</td>\n",
       "      <td>Clive Drake (United Kingdom) 12th November 2016</td>\n",
       "      <td>✅ Verified Review |  The flight started badly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>4</td>\n",
       "      <td>\"bit amateur for business class \"</td>\n",
       "      <td>R Gordon (United Kingdom) 11th November 2016</td>\n",
       "      <td>Gatwick to Alicante. Crew friendly but a bit a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>3</td>\n",
       "      <td>\"was one bad trip too many\"</td>\n",
       "      <td>P Cleary (United Kingdom) 10th November 2016</td>\n",
       "      <td>✅ Verified Review |  London Heathrow to Bangko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1</td>\n",
       "      <td>\"plane very dated and dirty\"</td>\n",
       "      <td>Sheila Gale (United Kingdom) 10th November 2016</td>\n",
       "      <td>London Gatwick to Barbados return. British Air...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ratingValue                             reviewTitle  \\\n",
       "0               8           \"sufficient leg and arm room\"   \n",
       "1               7                      “crew were polite”   \n",
       "2               2  \"Angry, disappointed, and unsatisfied\"   \n",
       "3               3       \"BA now stands for Basic Airways\"   \n",
       "4               8         \"A totally unremarkable flight\"   \n",
       "...           ...                                     ...   \n",
       "1995            3      \"another underwhelming experience\"   \n",
       "1996            3    \"underwhelming due to bean counters\"   \n",
       "1997            4       \"bit amateur for business class \"   \n",
       "1998            3             \"was one bad trip too many\"   \n",
       "1999            1            \"plane very dated and dirty\"   \n",
       "\n",
       "                                               location  \\\n",
       "0     Graeme Boothman (United Kingdom) 8th November ...   \n",
       "1            R Vines (United Kingdom) 7th November 2023   \n",
       "2              Massimo Tricca (Italy) 5th November 2023   \n",
       "3             J Kaye (United Kingdom) 5th November 2023   \n",
       "4                  M Collie (Ireland) 4th November 2023   \n",
       "...                                                 ...   \n",
       "1995    Clive Drake (United Kingdom) 13th November 2016   \n",
       "1996    Clive Drake (United Kingdom) 12th November 2016   \n",
       "1997       R Gordon (United Kingdom) 11th November 2016   \n",
       "1998       P Cleary (United Kingdom) 10th November 2016   \n",
       "1999    Sheila Gale (United Kingdom) 10th November 2016   \n",
       "\n",
       "                                          reviewArticle  \n",
       "0     ✅ Trip Verified |  Booked online months ago an...  \n",
       "1     ✅ Trip Verified |  The flight was on time. The...  \n",
       "2     Not Verified |  Angry, disappointed, and unsat...  \n",
       "3     ✅ Trip Verified |  As an infrequent flyer, Bri...  \n",
       "4     Not Verified |  A totally unremarkable flight,...  \n",
       "...                                                 ...  \n",
       "1995  ✅ Verified Review |  The flight started in the...  \n",
       "1996  ✅ Verified Review |  The flight started badly ...  \n",
       "1997  Gatwick to Alicante. Crew friendly but a bit a...  \n",
       "1998  ✅ Verified Review |  London Heathrow to Bangko...  \n",
       "1999  London Gatwick to Barbados return. British Air...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dataframe into csv file\n",
    "# df.to_csv('BA.csv', index=False)\n",
    "\n",
    "# Read csv\n",
    "df = pd.read_csv('BA.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to clean\n",
    "1. Convert ratingValue to int\n",
    "2. Remove quotation symbols from reviewTitle and convert to string\n",
    "3. Get text inside bracket in location and convert to string\n",
    "4. Split reviewArticle into verification and actual article columns\n",
    "5. Remove check symbol from verification column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "df['ratingValue'] = df['ratingValue'].astype(int) # Convert ratingValue to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "df['location'] = df['location'].astype(str)   # Convert to string\n",
    "df['year'] = df.location.str[-4:]\n",
    "df['location'] = df['location'].str.extract(r'\\((.*?)\\)')    # Get text inside bracket\n",
    "df['location'] = df['location'].str.lower()\n",
    "df['location'] = df['location'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I only want data from the past 5 years i.e 2018-2023 so I'd be dropping rows where year isn't >= 2018 \n",
    "df['year'] = df['year'].astype(int) # Convert ratingValue to float\n",
    "df = df[df.year >= 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1332 entries, 0 to 1331\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   ratingValue    1332 non-null   int32 \n",
      " 1   reviewTitle    1332 non-null   object\n",
      " 2   location       1332 non-null   object\n",
      " 3   reviewArticle  1332 non-null   object\n",
      " 4   year           1332 non-null   int32 \n",
      "dtypes: int32(2), object(3)\n",
      "memory usage: 52.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>reviewTitle</th>\n",
       "      <th>location</th>\n",
       "      <th>reviewArticle</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>\"sufficient leg and arm room\"</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>✅ Trip Verified |  Booked online months ago an...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>“crew were polite”</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>✅ Trip Verified |  The flight was on time. The...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Angry, disappointed, and unsatisfied\"</td>\n",
       "      <td>italy</td>\n",
       "      <td>Not Verified |  Angry, disappointed, and unsat...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"BA now stands for Basic Airways\"</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>✅ Trip Verified |  As an infrequent flyer, Bri...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>\"A totally unremarkable flight\"</td>\n",
       "      <td>ireland</td>\n",
       "      <td>Not Verified |  A totally unremarkable flight,...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>1</td>\n",
       "      <td>\"go with a budget airline\"</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>✅ Trip Verified |  Amsterdam to London. Servic...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>8</td>\n",
       "      <td>\"I was pleasantly surprised\"</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>✅ Trip Verified |  London to Johannesburg. I w...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>1</td>\n",
       "      <td>\"BA is now as bad as Ryanair\"</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>✅ Trip Verified |  Will never fly with BA agai...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>1</td>\n",
       "      <td>\"waiting on my luggage for five days\"</td>\n",
       "      <td>united states</td>\n",
       "      <td>✅ Trip Verified |  London to Tel Aviv.  I have...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>3</td>\n",
       "      <td>\"I was sorely disappointed\"</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>✅ Trip Verified | I flew Premium Economy from ...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ratingValue                             reviewTitle        location  \\\n",
       "0               8           \"sufficient leg and arm room\"  united kingdom   \n",
       "1               7                      “crew were polite”  united kingdom   \n",
       "2               2  \"Angry, disappointed, and unsatisfied\"           italy   \n",
       "3               3       \"BA now stands for Basic Airways\"  united kingdom   \n",
       "4               8         \"A totally unremarkable flight\"         ireland   \n",
       "...           ...                                     ...             ...   \n",
       "1327            1              \"go with a budget airline\"  united kingdom   \n",
       "1328            8            \"I was pleasantly surprised\"  united kingdom   \n",
       "1329            1           \"BA is now as bad as Ryanair\"  united kingdom   \n",
       "1330            1   \"waiting on my luggage for five days\"   united states   \n",
       "1331            3             \"I was sorely disappointed\"  united kingdom   \n",
       "\n",
       "                                          reviewArticle  year  \n",
       "0     ✅ Trip Verified |  Booked online months ago an...  2023  \n",
       "1     ✅ Trip Verified |  The flight was on time. The...  2023  \n",
       "2     Not Verified |  Angry, disappointed, and unsat...  2023  \n",
       "3     ✅ Trip Verified |  As an infrequent flyer, Bri...  2023  \n",
       "4     Not Verified |  A totally unremarkable flight,...  2023  \n",
       "...                                                 ...   ...  \n",
       "1327  ✅ Trip Verified |  Amsterdam to London. Servic...  2018  \n",
       "1328  ✅ Trip Verified |  London to Johannesburg. I w...  2018  \n",
       "1329  ✅ Trip Verified |  Will never fly with BA agai...  2018  \n",
       "1330  ✅ Trip Verified |  London to Tel Aviv.  I have...  2018  \n",
       "1331  ✅ Trip Verified | I flew Premium Economy from ...  2018  \n",
       "\n",
       "[1332 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "df['reviewTitle'] = df['reviewTitle'].str.lower()\n",
    "df['reviewTitle'] = df['reviewTitle'].str.replace('“','\\\"') \n",
    "df['reviewTitle'] = df['reviewTitle'].str.replace('”','\\\"')\n",
    "df['reviewTitle'] = df['reviewTitle'].str.extract(r'\\\"(.*?)\\\"')  # Get text in quotation symbols\n",
    "df['reviewTitle'] = df['reviewTitle'].str.strip()\n",
    "\n",
    "def cleanTitle(reviewTitle):\n",
    "    reviewTitle = re.sub(':','',str(reviewTitle))  # Removing the : symbols\n",
    "    reviewTitle = re.sub('\\\"','',str(reviewTitle)) # Removing the \" symbols\n",
    "    reviewTitle = re.sub('\\”','',str(reviewTitle)) # Removing the ” symbols\n",
    "    reviewTitle = re.sub('\\“','',str(reviewTitle)) # Removing the “ symbols\n",
    "    reviewTitle = re.sub('\\’','',str(reviewTitle)) # Removing the ’ symbols\n",
    "    reviewTitle = re.sub('\\/','',str(reviewTitle)) # Removing the / symbols\n",
    "    reviewTitle = re.sub('\\|','',str(reviewTitle)) # Removing the | symbols\n",
    "    reviewTitle = re.sub('\\?','',str(reviewTitle)) # Removing the ? symbols\n",
    "    reviewTitle = re.sub('\\.','',str(reviewTitle)) # Removing the . symbols\n",
    "    reviewTitle = re.sub('\\,','',str(reviewTitle)) # Removing the , symbols\n",
    "    reviewTitle = re.sub('\\!','',str(reviewTitle)) # Removing the ! symbols\n",
    "    reviewTitle = re.sub('-','',str(reviewTitle)) # Removing the - symbols\n",
    "    reviewTitle = re.sub('\\'','',str(reviewTitle)) # Removing the ' symbols\n",
    "    reviewTitle = re.sub('\\*','',str(reviewTitle)) # Removing the * symbols\n",
    "    reviewTitle = re.sub('[0-9]','',str(reviewTitle)) # Removing digits\n",
    "    return reviewTitle\n",
    "\n",
    "\n",
    "df['cleanTitle'] = df['reviewTitle'].apply(cleanTitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "df['reviewArticle'] = df['reviewArticle'].astype(str)   # Convert to string\n",
    "df['reviewArticle'] = df['reviewArticle'].str.lower()\n",
    "df['reviewArticle'] = df['reviewArticle'].str.strip()\n",
    "df[['Verification','reviewArticle']] = df['reviewArticle'].str.split('|',expand=True)\n",
    "\n",
    "\n",
    "def cleanArticle(reviewArticle):\n",
    "    reviewArticle = re.sub(':','',str(reviewArticle))  # Removing the : symbols\n",
    "    reviewArticle = re.sub('\\\"','',str(reviewArticle)) # Removing the \" symbols\n",
    "    reviewArticle = re.sub('\\”','',str(reviewArticle)) # Removing the ” symbols\n",
    "    reviewArticle = re.sub('\\“','',str(reviewArticle)) # Removing the “ symbols\n",
    "    reviewArticle = re.sub('\\’','',str(reviewArticle)) # Removing the ’ symbols\n",
    "    reviewArticle = re.sub('\\/','',str(reviewArticle)) # Removing the / symbols\n",
    "    reviewArticle = re.sub('\\|','',str(reviewArticle)) # Removing the | symbols\n",
    "    reviewArticle = re.sub('\\?','',str(reviewArticle)) # Removing the ? symbols\n",
    "    reviewArticle = re.sub('\\.','',str(reviewArticle)) # Removing the . symbols\n",
    "    reviewArticle = re.sub('\\,','',str(reviewArticle)) # Removing the , symbols\n",
    "    reviewArticle = re.sub('\\!','',str(reviewArticle)) # Removing the ! symbols\n",
    "    reviewArticle = re.sub('-','',str(reviewArticle)) # Removing the - symbols\n",
    "    reviewArticle = re.sub('\\'','',str(reviewArticle)) # Removing the ' symbols\n",
    "    reviewArticle = re.sub('\\*','',str(reviewArticle)) # Removing the * symbols\n",
    "    reviewArticle = re.sub('[0-9]','',str(reviewArticle)) # Removing digits\n",
    "    return reviewArticle\n",
    "\n",
    "df['cleanArticle'] = df['reviewArticle'].apply(cleanArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def cleanVerification(Verification):\n",
    "\n",
    "    Verification = re.sub('✅ trip verified','yes',Verification)\n",
    "    Verification = re.sub('not verified','no',Verification)\n",
    "\n",
    "    return Verification\n",
    "\n",
    "df['confirmedVerification'] = df['Verification'].apply(cleanVerification)\n",
    "\n",
    "df.drop(columns=['Verification','reviewArticle', 'reviewTitle'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING\n",
    "\n",
    " - Tokenization: This is breaking the raw text into small chunks(words, sentences) called tokens. These tokens help in understanding the context or developing the model for NLP. Tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words.\n",
    "\n",
    " - Stop words Removal: Stop words are commonly used words which are generally filtered out before processing a natural language. These are actually the most common words in any language (like articles, prepositions, pronouns, conjunctions, etc) and do not add much information to the text\n",
    "\n",
    "  - Lemmatization entails reducing a word to its dictionary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\23490\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23490\\Documents\\my portfolio\\BA Virtual Internship\\My method BA virtual copy.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m  \u001b[39m# text analysis\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mstopwords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m stop \u001b[39m=\u001b[39m stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m stop2 \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mive\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39myoure\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39myouve\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39myoull\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39myoud\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mshes\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mthatll\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdont\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mshouldve\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39marent\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcouldnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdidnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdoesnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhadnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhasnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhavent\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39misnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmightnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmustnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mneednt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mshant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mshouldnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwasnt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwerent\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwont\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwouldnt\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mtheres\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mthere\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mba\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbritish airways\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mairways\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbritish\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m stop\u001b[39m.\u001b[39mextend(stop2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk  # text analysis\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop2 = [\"ive\", \"im\", \"youre\", \"youve\", \"youll\", \"youd\", \"shes\", \"thatll\", \"dont\", \n",
    "                \"shouldve\", \"arent\", \"couldnt\", \"didnt\", \"doesnt\", \"hadnt\", \"hasnt\", \"havent\",\n",
    "                 \"isnt\", \"mightnt\", \"mustnt\", \"neednt\", \"shant\", \"shouldnt\", \"wasnt\", \"werent\", \"wont\", 'wouldnt',\n",
    "                'theres', \"there'is\", \"ba\", \"british airways\", \"airways\", \"british\"]\n",
    "\n",
    "stop.extend(stop2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23490\\Documents\\my portfolio\\BA Virtual Internship\\My method BA virtual copy.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     lemma_words \u001b[39m=\u001b[39m [lemmatizer\u001b[39m.\u001b[39mlemmatize(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m title_tokens]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(lemma_words)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mprocessedTitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mcleanTitle\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(preprocessTitle)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mprocessedTitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mprocessedTitle\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(processedTitle)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:4774\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4664\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4665\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4666\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4669\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4670\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4671\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4672\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4673\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4772\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4773\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4774\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:1100\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1100\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:1151\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1150\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1151\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1152\u001b[0m             values,\n\u001b[0;32m   1153\u001b[0m             f,\n\u001b[0;32m   1154\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1155\u001b[0m         )\n\u001b[0;32m   1157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1158\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\_libs\\lib.pyx:2919\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\23490\\Documents\\my portfolio\\BA Virtual Internship\\My method BA virtual copy.ipynb Cell 20\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocessTitle\u001b[39m(cleanTitle):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     title_tokens \u001b[39m=\u001b[39m word_tokenize(cleanTitle)  \u001b[39m# convert string to tokens\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     filtered_title \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m title_tokens \u001b[39mif\u001b[39;00m x \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop] \u001b[39m# Remove stopwords\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     filtered_title \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(filtered_title)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(filtered_title)\n",
      "\u001b[1;32mc:\\Users\\23490\\Documents\\my portfolio\\BA Virtual Internship\\My method BA virtual copy.ipynb Cell 20\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocessTitle\u001b[39m(cleanTitle):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     title_tokens \u001b[39m=\u001b[39m word_tokenize(cleanTitle)  \u001b[39m# convert string to tokens\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     filtered_title \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m title_tokens \u001b[39mif\u001b[39;00m x \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop] \u001b[39m# Remove stopwords\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     filtered_title \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(filtered_title)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(filtered_title)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize # to create word tokens\n",
    "from nltk.stem import WordNetLemmatizer # to reduce words to orginal form\n",
    "\n",
    "def preprocessTitle(cleanTitle):\n",
    "\n",
    "    title_tokens = word_tokenize(cleanTitle)  # convert string to tokens\n",
    "    filtered_title = [x for x in title_tokens if x not in stop] # Remove stopwords\n",
    "    filtered_title = ' '.join(filtered_title)\n",
    "\n",
    "    return \"\".join(filtered_title)  # join words with a space in between them\n",
    "\n",
    "def processedTitle(processedTitle):\n",
    "\n",
    "    title_tokens = word_tokenize(processedTitle)  # convert string to tokens\n",
    "    lemmatizer = WordNetLemmatizer() # instatiate an object WordNetLemmatizer Class\n",
    "    lemma_words = [lemmatizer.lemmatize(x) for x in title_tokens]\n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "\n",
    "df['processedTitle'] = df['cleanTitle'].apply(preprocessTitle)\n",
    "df['processedTitle'] = df['processedTitle'].apply(processedTitle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratingValue</th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>cleanTitle</th>\n",
       "      <th>cleanArticle</th>\n",
       "      <th>confirmedVerification</th>\n",
       "      <th>processedTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2023</td>\n",
       "      <td>sufficient leg and arm room</td>\n",
       "      <td>booked online months ago and the only hitch ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>sufficient leg arm room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2023</td>\n",
       "      <td>crew were polite</td>\n",
       "      <td>the flight was on time the crew were polite ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>crew polite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>italy</td>\n",
       "      <td>2023</td>\n",
       "      <td>angry disappointed and unsatisfied</td>\n",
       "      <td>angry disappointed and unsatisfied my route ...</td>\n",
       "      <td>no</td>\n",
       "      <td>angry disappointed unsatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>2023</td>\n",
       "      <td>ba now stands for basic airways</td>\n",
       "      <td>as an infrequent flyer british airways was a...</td>\n",
       "      <td>yes</td>\n",
       "      <td>stand basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>ireland</td>\n",
       "      <td>2023</td>\n",
       "      <td>a totally unremarkable flight</td>\n",
       "      <td>a totally unremarkable flight on time as com...</td>\n",
       "      <td>no</td>\n",
       "      <td>totally unremarkable flight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratingValue        location  year                          cleanTitle  \\\n",
       "0            8  united kingdom  2023         sufficient leg and arm room   \n",
       "1            7  united kingdom  2023                    crew were polite   \n",
       "2            2           italy  2023  angry disappointed and unsatisfied   \n",
       "3            3  united kingdom  2023     ba now stands for basic airways   \n",
       "4            8         ireland  2023       a totally unremarkable flight   \n",
       "\n",
       "                                        cleanArticle confirmedVerification  \\\n",
       "0    booked online months ago and the only hitch ...                  yes    \n",
       "1    the flight was on time the crew were polite ...                  yes    \n",
       "2    angry disappointed and unsatisfied my route ...                   no    \n",
       "3    as an infrequent flyer british airways was a...                  yes    \n",
       "4    a totally unremarkable flight on time as com...                   no    \n",
       "\n",
       "                   processedTitle  \n",
       "0         sufficient leg arm room  \n",
       "1                     crew polite  \n",
       "2  angry disappointed unsatisfied  \n",
       "3                     stand basic  \n",
       "4     totally unremarkable flight  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize # to create word tokens\n",
    "from nltk.stem import WordNetLemmatizer # to reduce words to orginal form\n",
    "\n",
    "def preprocessArticle(cleanArticle):\n",
    "\n",
    "    Article_tokens = word_tokenize(cleanArticle)  # convert string to tokens\n",
    "    filtered_Article = [x for x in Article_tokens if x not in stop] # Remove stopwords\n",
    "    filtered_Article = ' '.join(filtered_Article)\n",
    "\n",
    "    return \"\".join(filtered_title)  # join words with a space in between them\n",
    "\n",
    "def processedArticle(processedArticle):\n",
    "\n",
    "    Article_tokens = word_tokenize(processedArticle)  # convert string to tokens\n",
    "    lemmatizer = WordNetLemmatizer() # instatiate an object WordNetLemmatizer Class\n",
    "    lemma_words = [lemmatizer.lemmatize(x) for x in Article_tokens]\n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "\n",
    "df['processedArticle'] = df['cleanArticle'].apply(preprocessArticle)\n",
    "df['processedArticle'] = df['processedArticle'].apply(processedArticle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\23490\\Documents\\my portfolio\\BA Virtual Internship\\My method BA virtual copy.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/23490/Documents/my%20portfolio/BA%20Virtual%20Internship/My%20method%20BA%20virtual%20copy.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df1 \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize # to create word tokens\n",
    "from nltk.stem import WordNetLemmatizer # to reduce words to orginal form\n",
    "\n",
    "def preprocessArticle(cleanArticle):\n",
    "\n",
    "    Article_tokens = word_tokenize(cleanArticle)  # convert string to tokens\n",
    "\n",
    "    filtered_Article = [x for x in Article_tokens if x not in stop] # Remove stopwords\n",
    "\n",
    "    lemma_words = [lemmatizer.lemmatize(x) for x in filtered_Article]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() # instatiate an object WordNetLemmatizer Class\n",
    "    \n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "\n",
    "df1['processedArticle'] = df1['cleanArticle'].apply(preprocessArticle)\n",
    "df1['processedArticle'] = df1['processedArticle'].apply(processedArticle)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
